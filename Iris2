# -*- coding: utf-8 -*-
"""Copy of Project - Web Application for Data Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P02bO5bs-iV4xLsVb6gbXdrqpDSH7Awa

# Project - Web Application for Data Analytics

## About the instructor:

**Ts. Nur Shakirah Md Salleh**

Lead Technical Trainer - Data, Analytic and Machine Learning

airasia academy

nurshakirahmdsalleh@airasiaacademy.com

LinkedIn: [Ts. Nur Shakirah Md Salleh](https://www.linkedin.com/in/nurshakirahmdsalleh)

Â©2023 [airasia academy](https://airasiaacademy.com) All rights reserved.

#Project

Instructions:
1. Develop a Python website to predict the target and deploy it using Streamlit using GitHub repository.
2. You are require to use `Advertising.csv` dataset (Team Krypton) and `iris` dataset (Team Asgard) in this case study. Generate the model of this dataset outside of the streamlit environment (You can use Google Colab). You just need to load the model in this app (no model training should happens in this application).
3. You are require to choose only **ONE** of the most suitable supervised machine learning algorithm to solve this problem.
4. Feature scaling is optional for this project.
5. You need to enable slider to set the feature values.


**Submission**

Submit the following information:
* source code to generate the model (.pdf)
* screenshot of the source code (.py) on GitHub
* screenshot of the streamlit app
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

pd.options.display.max_columns = None
pd.options.display.max_rows = None

df = sns.load_dataset("iris")

df.shape

df.head()

df.dtypes

df.info()

df.isnull().sum()

df.species.unique()

df.species.value_counts()

df.describe()

df.plot.hist()

from sklearn.model_selection import train_test_split
import tensorflow as tf

X=df.drop('species', axis=1)
y=df.species.copy()

X

from sklearn import preprocessing
scaler = preprocessing.MinMaxScaler()
scaled = scaler.fit_transform(X)
df_scaled = pd.DataFrame(scaled)
df_scaled.columns = ['sepal_length','sepal_width', 'petal_length','petal_width']
df_scaled.head()

df_scaled.plot.hist()

#training and testing split using all feature
X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=1, stratify=y)

print(X_train.shape)
print(y_train.shape)

print(X_test.shape)
print(y_test.shape)

X_train

from sklearn import tree
from sklearn.tree import plot_tree
from sklearn.metrics import confusion_matrix

modeldt = tree.DecisionTreeClassifier()
modeldt = modeldt.fit(X_train, y_train)

y_pred = modeldt.predict(X_test)

confusion_matrix_df = pd.crosstab(y_test, y_pred,
                                  rownames=['Actual'],
                                  colnames=['Predicted'],
                                  margins=True)
print(confusion_matrix_df)

from sklearn.metrics import accuracy_score
y_pred = modeldt.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

import pickle
model_filename = 'modeldt.pkl'

with open(model_filename, 'wb') as file:
    pickle.dump(modeldt, file)

print(f"modeldt saved to {modeldt}")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile DecisionTreeClassifier.py
# 
# st.write("# Simple Iris Flower Prediction App")
# st.write("This app predicts the **Iris flower** type!")
# 
# st.sidebar.header('User Input Parameters')
# 
# def user_input_features():
#     sepal_length = st.sidebar.slider('Sepal length', 4.3, 7.9, 5.4) #min,max,default
#     sepal_width = st.sidebar.slider('Sepal width', 2.0, 4.4, 3.4)
#     petal_length = st.sidebar.slider('Petal length', 1.0, 6.9, 1.3)
#     petal_width = st.sidebar.slider('Petal width', 0.1, 2.5, 0.2)
#     data = {'sepal_length': sepal_length,
#             'sepal_width': sepal_width,
#             'petal_length': petal_length,
#             'petal_width': petal_width}
#     features = pd.DataFrame(data, index=[0])
#     return features
# 
# df = user_input_features()
# 
# st.subheader('User Input parameters')
# st.write(df)
# 
# prediction = modeldt.predict(df)
# prediction_proba = modeldt.predict_proba(df)
# 
# st.subheader('Class labels and their corresponding index number')
# st.write(Y.unique())
# 
# st.subheader('Prediction')
# st.write(prediction)
# 
# st.subheader('Prediction Probability')
# st.write(prediction_proba)
#
